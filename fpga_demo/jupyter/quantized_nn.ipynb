{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9b02af22-735d-48ee-8f18-2a955e216161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class IntegerLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        # Initialize weights as floating-point values\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features, dtype=torch.float32))  # Use normal distribution for initialization\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.mm(x, self.weight.t())\n",
    "    \n",
    "    def quantize_weights(self, target_min=-128, target_max=127):\n",
    "        \"\"\"Quantize the weights to a target range with dynamic scaling.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Find the min and max of the weights\n",
    "            weight_min = self.weight.min()\n",
    "            weight_max = self.weight.max()\n",
    "            \n",
    "            # Dynamically scale the target range based on observed weight distribution\n",
    "            scale_factor = 0.3 # Adjust this factor to control how aggressively the weights are scaled\n",
    "            range_span = (weight_max - weight_min) * scale_factor\n",
    "            target_min_scaled = weight_min - range_span / 2\n",
    "            target_max_scaled = weight_max + range_span / 2\n",
    "            \n",
    "            # Scale the weights to the scaled target range\n",
    "            scale = (target_max_scaled - target_min_scaled) / (weight_max - weight_min)\n",
    "            zero_point = target_min_scaled - weight_min * scale\n",
    "            \n",
    "            # Quantize the weights\n",
    "            quantized_weights = torch.round(self.weight * scale + zero_point)\n",
    "            \n",
    "            # Clip the values to ensure they are within the target range\n",
    "            quantized_weights = torch.clamp(quantized_weights, target_min, target_max)\n",
    "            \n",
    "            # Store the quantized weights back into the model\n",
    "            self.weight.data = quantized_weights\n",
    "    \n",
    "class IntegerNet(nn.Module):\n",
    "    def __init__(self, input_size=784):\n",
    "        super().__init__()\n",
    "        # Four layers of IntegerLinear\n",
    "        self.layer1 = IntegerLinear(input_size, 128)\n",
    "        self.layer2 = IntegerLinear(128, 128)\n",
    "        self.layer3 = IntegerLinear(128, 64)\n",
    "        self.layer4 = IntegerLinear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def quantize_weights(self):\n",
    "        \"\"\"Quantize weights for all layers.\"\"\"\n",
    "        self.layer1.quantize_weights()\n",
    "        self.layer2.quantize_weights()\n",
    "        self.layer3.quantize_weights()\n",
    "        self.layer4.quantize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "fbac7b07-ebf2-4ad4-934a-e989818ce91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath='train.csv'):\n",
    "    data = pd.read_csv(filepath)\n",
    "    labels = data['label'].values\n",
    "    pixels = data.drop('label', axis=1).values\n",
    "    \n",
    "    # Convert to binary (0 or 1)\n",
    "    pixels = (pixels > 127).astype(np.float32)\n",
    "    \n",
    "    return torch.FloatTensor(pixels), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "7cc5a6eb-63a3-46b9-9cdf-57ead970f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, epochs=10, batch_size=128):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "    \n",
    "    n_samples = X_train.shape[0]\n",
    "    n_batches = n_samples // batch_size\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        # Shuffle data\n",
    "        indices = torch.randperm(n_samples)\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            \n",
    "            batch_X = X_train[start_idx:end_idx]\n",
    "            batch_y = y_train[start_idx:end_idx]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        avg_loss = total_loss / n_batches\n",
    "        accuracy = correct / n_samples\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "        \n",
    "        # Quantize weights after each epoch to reduce their size\n",
    "        model.quantize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fb20667a-dffa-474b-aa08-be43c7449abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data()\n",
    "model = IntegerNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "03c0c3f3-6fc6-475b-a403-cfd0c19c0a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 236.2272, Accuracy: 0.3083\n",
      "Epoch [2/10], Loss: 11.6330, Accuracy: 0.1227\n",
      "Epoch [3/10], Loss: 14.5360, Accuracy: 0.1112\n",
      "Epoch [4/10], Loss: 16.4991, Accuracy: 0.1039\n",
      "Epoch [5/10], Loss: 15.7448, Accuracy: 0.1023\n",
      "Epoch [6/10], Loss: 14.8864, Accuracy: 0.1000\n",
      "Epoch [7/10], Loss: 13.2210, Accuracy: 0.0992\n",
      "Epoch [8/10], Loss: 25.8806, Accuracy: 0.0989\n",
      "Epoch [9/10], Loss: 19.4008, Accuracy: 0.0986\n",
      "Epoch [10/10], Loss: 7.0968, Accuracy: 0.0987\n"
     ]
    }
   ],
   "source": [
    "train_model(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2de987f3-e0bb-42fd-aa65-b038bd166cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Weight Matrices ---\n",
      "layer1.weight:\n",
      "tensor([  1.,  -1.,   1.,   1.,   0., -28.,  -1.,   1.,  -1.,  27.,   1.,  27.,\n",
      "          1.,  -2.,   1.,  -1.,   0., -36.,  27.,  27.,   1.,   0.,  -1.,   0.,\n",
      "         -2.,  27.,  35.,  -2., -28.,   1.,   1.,   0.,   1.,   0.,  -2.,  -2.,\n",
      "          0.,   0.,   0.,   0.,   0.,  27.,   0.,  27.,  -1.,   1.,  -1.,  -1.,\n",
      "          0.,   0.,   0.,   0.,  27.,  -2., -28.,  -2.,   1.,   1.,  27.,   1.,\n",
      "         -2.,   1.,   1.,   1.,   1.,  -2.,   0.,  27.,   0.,   0.,   1.,  -2.,\n",
      "          1.,   1.,   1.,  -1.,  -1.,  -1.,  -1.,   0.,  -1.,  -1.,   0.,  27.,\n",
      "          0.,   1.,   0.,   0.,   1.,   0.,   1.,   0.,  -1.,   1.,   0.,  -2.,\n",
      "          0.,  -1.,  35., -36.,  -2.,   0.,   0.,   1.,   1.,  -1.,  -1.,  27.,\n",
      "          0.,   0., -28.,  -1.,  -1.,  27.,   1., -28.,  -1.,   0.,  -2.,   1.,\n",
      "         -1.,   1.,  -1.,  -1., -28.,   1.,   1.,   0.,  35.,  -2.,   0.,   0.,\n",
      "         -2.,  -2.,  -1.,   1.,   0.,   0.,  27.,  27.,  35.,   1.,  27.,   1.,\n",
      "          1.,   1.,   1.,   0.,   1.,  -2.,   1.,  -1.,  27.,   1.,  -1.,   0.,\n",
      "         -1., -28.,   1.,   0.,  -1.,   0.,   0.,   1.,  27.,   1.,   0.,   0.,\n",
      "         27.,  -1.,  -1.,  27.,   1.,   0.,   0.,  -2.,  -2.,   0.,   1.,  -2.,\n",
      "          1.,  -1.,  27.,  -1.,  35.,   1.,  -1.,  -1.,   1.,   0.,   0.,  -2.,\n",
      "         -1.,  -1.,  -1.,   0.,  -1.,   1.,  -1.,   0.,  27.,  -2.,  27.,  -1.,\n",
      "         27.,  -2.,  35.,   1.,  27.,  27.,   0.,   0.,  27.,  35.,  -1.,   1.,\n",
      "          1.,  -1.,   0.,  -1., -28.,   1.,  27.,   1.,   0.,  -1.,  -2.,  27.,\n",
      "         -1.,  -1.,   0.,   1.,   0.,  -2.,  -1.,   1.,   1.,   1., -28.,   0.,\n",
      "         -1.,   1.,  27.,  -1.,   0.,  -1.,  -1.,   0.,   1.,   0.,   1.,  -1.,\n",
      "         27.,  -2.,  -1.,   0.,   0.,   0.,   0.,  -1.,  -2., -28.,   0.,   1.,\n",
      "         27.,  27.,  -1.,   1.,   1.,   1.,  35., -28.,  27.,   1.,  27.,  -1.,\n",
      "          0., -28.,   0.,   0.,   0.,  -1.,   0.,   0.,  -2.,   0.,   1.,   1.,\n",
      "          1.,   0.,   0., -28.,  27.,  35.,  27.,  35.,  27.,   1.,  -1.,   1.,\n",
      "         -2.,  -1.,   1.,   0.,   0.,   1., -28.,   1.,   1.,  -2.,   0.,  27.,\n",
      "         27.,   0.,   1., -28.,  -1.,  -1.,  -1.,  -1.,   0.,  -1.,   1.,   0.,\n",
      "          1.,   0.,   0.,   1.,   0.,   1.,   0.,  -1.,   0.,  -1.,   0.,  -2.,\n",
      "         -2.,  -1.,   1.,   0.,  27.,   0.,  -1.,  -1.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,  27.,   1.,   1.,  -1.,  -1.,  -2.,   1.,   0.,  27.,  27.,\n",
      "         -1.,   0.,   1.,  -2.,  27.,   0.,   1.,   0.,  -1.,   1.,  -2.,  -2.,\n",
      "         27.,   0.,  27.,  -1.,   1.,   1.,   0.,  27.,  27.,   0.,   1.,   0.,\n",
      "         -1.,   1.,  -1.,   0.,   1.,  -1.,   0.,  35.,  27.,  27.,   0., -28.,\n",
      "         -2.,  -1.,  27.,  -1.,  -1.,  -1.,  27.,  -2.,   0.,  -3.,  -2.,   0.,\n",
      "         27.,  27.,   0.,  27.,   0.,  -1.,  -2.,  35.,  27.,  27.,   0.,  -1.,\n",
      "         -2.,   0.,  -1.,  35.,   0.,   0.,  -1.,   1.,   0.,  -2.,   1.,  -1.,\n",
      "         -1.,  -1.,   0.,   0.,  -1.,  -1.,  27.,  -1.,  -1.,   0.,  -1.,  27.,\n",
      "         -2.,   1.,   1.,   1.,  -2.,   1.,  -2.,   1.,   1.,   1.,  -1.,   0.,\n",
      "         -1.,   1.,   0.,  27., -28.,   1.,  -1.,   0.,   0.,  -2.,  -1.,  -1.,\n",
      "          1.,   0.,   1.,   1.,  -2.,   0.,   0.,   0.,  -1.,  27.,   0.,  -1.,\n",
      "          0.,   0.,  27.,   1.,  35.,  27.,   0.,   0.,   0.,  27.,   0.,  27.,\n",
      "         -2.,   1.,  27.,   1.,  -1.,   0.,   1.,   0.,  -1.,   0.,   0.,   1.,\n",
      "         -1.,   0.,   0.,  -2.,  -1.,  -2.,  -1.,   1.,  27.,  27.,  -1.,  27.,\n",
      "          0.,   1.,   1.,  -1.,   0.,   0.,   1.,   1.,  27.,   0.,  -1., -28.,\n",
      "         -2.,  -1.,   0.,   0.,   1.,   1.,  -1.,   0.,   1.,  27.,  27.,   0.,\n",
      "         -2.,   0.,  -2.,  -2.,  27.,  35.,   1.,   0.,   0.,   1.,   1.,   0.,\n",
      "         -1.,   0.,   1.,   0.,  -1.,  -1.,   0.,  27.,  27.,   0.,  -1.,  -1.,\n",
      "         -2.,  -2.,   0.,   0.,  -1.,  -2.,   0.,   0.,   1.,  -1.,  -2.,   1.,\n",
      "          1.,   0.,  27.,   1.,  -1.,   0.,   0.,   1.,  -1.,   0.,   0.,   1.,\n",
      "          0.,  -1.,  27.,   1.,   0.,   1.,  -2.,  -1.,  -1.,  27.,  -2.,  -2.,\n",
      "          1.,  -1.,  27.,   0.,   1.,   0.,  -2.,   0., -28.,  -1.,   0.,   1.,\n",
      "         -2.,  -1.,  -1.,   0.,   1.,   0.,  27.,   0.,   0.,   1.,  -1.,   1.,\n",
      "          1.,  -1.,  -1.,  27.,   0.,   0.,   0.,  -1.,   0.,   0.,   0.,  -1.,\n",
      "          0.,   1.,  27.,  -2.,   1.,  -2.,   0.,   1.,  35.,   1.,   0.,   1.,\n",
      "         -2.,   1.,   1.,   0.,  35.,  -2.,   1.,   1.,   1.,   0.,   1.,   1.,\n",
      "         -1.,   1.,  27.,  -2.,   1.,  -2.,  -1.,  -2.,  -1.,   0.,  -1.,  46.,\n",
      "         27.,  -2.,  -1.,   0.,   1.,  -1.,   1.,  -2.,   0.,   1.,  -1.,   1.,\n",
      "          1.,  -1.,  -1.,   1.,   1.,  27.,  -1.,   1.,   0.,  -2.,  -1.,  -1.,\n",
      "         35.,  -2.,  27.,   1.,  -2.,  -1.,   1.,  -1.,  -1.,  -1.,  -1.,   0.,\n",
      "          0.,   0.,  -2.,   0.,   1.,  -2.,  -1.,  -1.,   0.,   1.,   0.,  46.,\n",
      "         -1.,   0.,  -2.,  -2.,  -2.,   1.,  -1.,   0.,  27.,   0.,  -2.,   0.,\n",
      "          0.,  -2.,   0.,  -1.,  27.,   0.,  -2.,   0.,  -1.,   0.,   0.,   0.,\n",
      "          0., -28.,   0.,   1.,   1.,   0.,  -1.,   0.,   0.,  27.,  -1.,   1.,\n",
      "          1.,  27.,  -2.,  -1.,   0., -28.,   1.,  -1.,  -1.,   0.,   0.,   0.,\n",
      "          0.,  -2.,   0.,   0.,  -1.,  -2.,  -1.,   0.,  -2.,   0.,   1.,   1.,\n",
      "         -1.,   0.,   0.,  -2.])\n",
      "\n",
      "layer2.weight:\n",
      "tensor([-22.,  -0.,   1.,  27., -22.,   0., -28.,  27.,   1.,  -0.,  -1.,  -1.,\n",
      "         29.,   1., -22.,   1., -22., -22.,  -0.,  -0.,  27.,  -0.,   1.,   1.,\n",
      "         -1.,  -1.,  -1.,   1.,  27.,   1.,  -1.,   0.,  -0.,   1.,  -1.,  27.,\n",
      "         -1., -35.,   1.,  -0.,  -1.,   1.,   1.,  -1.,  -1.,  -0.,   0.,   1.,\n",
      "          1., -22.,  -0.,   0.,  -1.,   1.,   1.,  -1.,   0.,  27.,   0.,   0.,\n",
      "          1.,  29.,   0.,   2.,  27.,  -1.,  27.,  -0.,   1.,  -1.,   0.,   1.,\n",
      "         -0.,   0.,  27.,  -1.,  -1.,   0.,   0.,   0.,   1.,  -0.,   0.,  -1.,\n",
      "          0.,  -0.,   0.,   0., -22.,   0.,   0.,   1.,  22., -22.,   0., -22.,\n",
      "        -22.,  27.,  -0.,   1.,  22.,  -1.,  -1.,  -0.,   1.,  -1.,   1.,  27.,\n",
      "          0., -38.,  -1.,   1.,  -1.,   1.,   0.,  27., -22.,   1.,   1.,  -1.,\n",
      "        -22.,   0.,  22.,   0., -22.,  -1.,  27.,  22.])\n",
      "\n",
      "layer3.weight:\n",
      "tensor([  0.,  -2.,  -2.,   0.,   0.,   0.,  35.,   1.,   0.,   0.,   1.,  -2.,\n",
      "         -1.,   0.,   0.,  -2.,  -1.,   0.,   1.,   0.,   0.,   0.,  -1.,  -1.,\n",
      "         -2.,   0.,   0.,   0.,  -1.,   0.,  -2.,  -1.,   0., -15.,   0.,  -1.,\n",
      "          0.,  -1.,  -1.,   0.,  -1.,  -1.,   0.,  -1.,   1.,   1.,  -2.,  -1.,\n",
      "          0.,  -1.,   1.,   1.,   0.,   0.,   0.,   0.,  -1.,  35.,  35.,   0.,\n",
      "          0.,  -1.,  -2.,  -2.,   0.,   1.,   1.,   0.,  -1.,   0.,   1.,  -2.,\n",
      "          0.,   0., -36.,  27.,   0., -28.,  -1.,  27.,  -1.,   1.,   1.,   0.,\n",
      "          0.,   0.,  -1.,  35.,  -1.,  -2.,   0.,   0.,  -1.,  27.,   0.,  -1.,\n",
      "        -10.,  -1.,  27.,   0.,  -1., -28.,  -1.,   1.,  27.,   0.,   0.,  -1.,\n",
      "          1.,  27.,   1.,   0.,   0.,   1.,  -1.,   0.,   1.,  -1.,   0.,  -1.,\n",
      "        -17.,  -1.,  -1.,  27.,   1.,  -2.,  -2.,   0.])\n",
      "\n",
      "layer4.weight:\n",
      "tensor([ 22., -22.,   1.,   1.,   1., -22.,  22.,  22.,   1.,   0.,  -1.,  -1.,\n",
      "          0.,  -1.,   1.,  29.,   1.,  -1.,  -1.,  -1.,   0.,  -1., -29.,   0.,\n",
      "          1.,   0., -22.,   0.,   0.,  -1.,  -0.,   0.,  -1., -29.,   1.,  22.,\n",
      "          0.,   0.,  -1.,  -1.,  -0.,  23.,   1.,   1.,  -1.,   0.,  -1., -22.,\n",
      "        -22.,  -0.,   0.,   0.,  -1.,   0., -22.,  -1.,   0.,   0.,   0.,  22.,\n",
      "          1.,   0., -22.,  -1.])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x29f5b5840>"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the end of training, print out all the weight matrices\n",
    "print(\"\\n--- Weight Matrices ---\")\n",
    "for name, param in model.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        print(f\"{name}:\\n{param.data[0]}\\n\")\n",
    "\n",
    "model.named_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
