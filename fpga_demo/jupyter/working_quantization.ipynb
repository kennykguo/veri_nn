{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d486bccd-5198-4554-9d25-99b2644b8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7be1392-0cdd-4d38-9f45-c25a0daa7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns data tensors for images and labels (binary values 0 and 1)\n",
    "def load_data(filepath='train.csv'):\n",
    "    data = pd.read_csv(filepath)\n",
    "    labels = data['label'].values\n",
    "    pixels = data.drop('label', axis=1).values\n",
    "    \n",
    "    # Convert to binary (0 or 1)\n",
    "    pixels = (pixels > 127).astype(np.float32)\n",
    "    \n",
    "    return torch.FloatTensor(pixels), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4b9ca-9a84-4922-9ee5-1990b705286d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47414e26-6d2b-4d97-a15c-405016c19e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67831646-2434-438a-b8ae-88893ad865ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44978fc-3d61-437c-a6ac-9213525d0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ScalableLinear layer without bias\n",
    "class ScalableLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features, dtype=torch.float32))  # Initialize weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.mm(x, self.weight.t())\n",
    "\n",
    "    def scale_weights(self, target_min, target_max):\n",
    "        \"\"\"Scale the weights of the layer to a desired integer range.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Get the min and max values of the layer's weights\n",
    "            weight_min = self.weight.min()\n",
    "            weight_max = self.weight.max()\n",
    "\n",
    "            # Compute scaling factor\n",
    "            scale = (target_max - target_min) / (weight_max - weight_min)\n",
    "            zero_point = target_min - weight_min * scale\n",
    "\n",
    "            # Apply scaling to weights\n",
    "            quantized_weights = torch.round(self.weight * scale + zero_point)\n",
    "\n",
    "            # Clip to the target range (make sure no value goes outside the desired range)\n",
    "            quantized_weights = torch.clamp(quantized_weights, target_min, target_max)\n",
    "\n",
    "            # Update weights with quantized values\n",
    "            self.weight.data = quantized_weights\n",
    "\n",
    "\n",
    " # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "# Define the neural network with scalable layers\n",
    "class ScalableNet(nn.Module):\n",
    "    def __init__(self, input_size=784):\n",
    "        super().__init__()\n",
    "        self.layer1 = ScalableLinear(input_size, 64)\n",
    "        self.layer2 = ScalableLinear(64, 64)\n",
    "        self.layer3 = ScalableLinear(64, 32)\n",
    "        self.layer4 = ScalableLinear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    # Helper function that scales weights directly\n",
    "    def scale_weights(self, target_min, target_max):\n",
    "        \"\"\"Scale weights for all layers.\"\"\"\n",
    "        self.layer1.scale_weights(target_min, target_max)\n",
    "        self.layer2.scale_weights(target_min, target_max)\n",
    "        self.layer3.scale_weights(target_min, target_max)\n",
    "        self.layer4.scale_weights(target_min, target_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f7f7b1-fa20-4125-9a86-dead9caec3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point in training loop that scales our weights\n",
    "def gradual_scale_weights(model, initial_target_min, initial_target_max, final_target_min, final_target_max, step_size, epoch, max_epochs):\n",
    "    \"\"\"\n",
    "    Gradually scale the weights of each layer after each epoch.\n",
    "    \"\"\"\n",
    "    # Compute the scaling range for this epoch based on the progress in training\n",
    "    scale_min = initial_target_min + (final_target_min - initial_target_min) * (epoch / max_epochs)\n",
    "    scale_max = initial_target_max + (final_target_max - initial_target_max) * (epoch / max_epochs)\n",
    "\n",
    "    # Apply gradual scaling to each layer\n",
    "    model.scale_weights(target_min=int(scale_min), target_max=int(scale_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a8a4ad6-ecdd-4aaf-8545-1a001fec219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data and preprocess it here\n",
    "X_train, y_train = load_data()\n",
    "\n",
    "# Train the model\n",
    "model = ScalableNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37d98d81-ccf0-48cd-9b68-3e458dda88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30\n",
    "batch_size = 128\n",
    "initial_target_min= -32\n",
    "initial_target_max= 31\n",
    "final_target_min= -128\n",
    "final_target_max= 127\n",
    "step_size= 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "n_samples = X_train.shape[0]\n",
    "n_batches = n_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad344b82-33c1-4e4e-bf4c-1daace77b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.4942, Accuracy: 0.3877\n",
      "Epoch [2/30], Loss: 62686.3156, Accuracy: 0.6056\n",
      "Epoch [3/30], Loss: 19606.2193, Accuracy: 0.7675\n",
      "Epoch [4/30], Loss: 19917.6780, Accuracy: 0.8119\n",
      "Epoch [5/30], Loss: 21908.1348, Accuracy: 0.8352\n",
      "Epoch [6/30], Loss: 24577.3792, Accuracy: 0.8507\n",
      "Epoch [7/30], Loss: 29386.0641, Accuracy: 0.8621\n",
      "Epoch [8/30], Loss: 33226.9711, Accuracy: 0.8699\n",
      "Epoch [9/30], Loss: 37997.2656, Accuracy: 0.8757\n",
      "Epoch [10/30], Loss: 43004.6519, Accuracy: 0.8816\n",
      "Epoch [11/30], Loss: 48877.4919, Accuracy: 0.8848\n",
      "Epoch [12/30], Loss: 56584.4659, Accuracy: 0.8916\n",
      "Epoch [13/30], Loss: 63764.6206, Accuracy: 0.8958\n",
      "Epoch [14/30], Loss: 71814.4586, Accuracy: 0.8972\n",
      "Epoch [15/30], Loss: 81569.3629, Accuracy: 0.8991\n",
      "Epoch [16/30], Loss: 93376.0606, Accuracy: 0.9001\n",
      "Epoch [17/30], Loss: 104841.4994, Accuracy: 0.9051\n",
      "Epoch [18/30], Loss: 116829.9022, Accuracy: 0.9057\n",
      "Epoch [19/30], Loss: 129064.4479, Accuracy: 0.9065\n",
      "Epoch [20/30], Loss: 141041.0925, Accuracy: 0.9086\n",
      "Epoch [21/30], Loss: 158094.2180, Accuracy: 0.9081\n",
      "Epoch [22/30], Loss: 175905.9735, Accuracy: 0.9122\n",
      "Epoch [23/30], Loss: 192685.5340, Accuracy: 0.9128\n",
      "Epoch [24/30], Loss: 213124.7591, Accuracy: 0.9141\n",
      "Epoch [25/30], Loss: 231825.2644, Accuracy: 0.9152\n",
      "Epoch [26/30], Loss: 253957.1224, Accuracy: 0.9155\n",
      "Epoch [27/30], Loss: 278286.6519, Accuracy: 0.9192\n",
      "Epoch [28/30], Loss: 303445.5762, Accuracy: 0.9197\n",
      "Epoch [29/30], Loss: 328230.6021, Accuracy: 0.9205\n",
      "Epoch [30/30], Loss: 360586.4806, Accuracy: 0.9207\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_X = X_train[start_idx:end_idx]\n",
    "        batch_y = y_train[start_idx:end_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pas\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / n_samples\n",
    "    accuracy = correct / n_samples\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Scale the weights using \n",
    "    # Gradual weight scaling after each epoch\n",
    "    gradual_scale_weights(model, initial_target_min, initial_target_max, final_target_min, final_target_max, step_size, epoch, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f83c1fc-852b-482c-a2e0-7e5a686cbd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check min and max values before and after scaling\n",
    "# print(\"Before scaling:\")\n",
    "# for layer in model.children():\n",
    "#     if isinstance(layer, ScalableLinear):\n",
    "#         print(f\"Layer weights min: {layer.weight.min().item()}, max: {layer.weight.max().item()}\")\n",
    "\n",
    "# # # Apply scaling\n",
    "# # model.scale_weights(target_min=-128, target_max=127)\n",
    "\n",
    "# print(\"\\nAfter scaling:\")\n",
    "# for layer in model.children():\n",
    "#     if isinstance(layer, ScalableLinear):\n",
    "#         print(f\"Layer weights min: {layer.weight.min().item()}, max: {layer.weight.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27b9eecd-9ebe-41de-aa78-da41b07c8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 62792664.0000, Test Accuracy: 0.9035\n"
     ]
    }
   ],
   "source": [
    "# Test the model after scaling the weights\n",
    "def test_model(model, X_test, y_test):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        loss = criterion(outputs, y_test)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == y_test).sum().item()\n",
    "        accuracy = correct / y_test.size(0)\n",
    "        \n",
    "    print(f\"Test Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "# Assuming you have the test set X_test and y_test available\n",
    "# Run the evaluation after scaling the weights\n",
    "# model.scale_weights(target_min=0, target_max=255)\n",
    "\n",
    "# Test the model after scaling\n",
    "test_model(model, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d20fe221-937b-408d-bf19-54570eeae69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Weights:\n",
      " tensor([[  1.,  38.,  61.,  ..., -40.,   7.,  32.],\n",
      "        [ 40.,   6.,   3.,  ...,   4.,   7.,   4.],\n",
      "        [ 40.,   1.,  37.,  ...,  -1.,  -0.,   4.],\n",
      "        ...,\n",
      "        [ 38.,  79.,  -1.,  ..., -30.,   7.,  -0.],\n",
      "        [  7.,  38.,  39.,  ...,  38., -34.,  32.],\n",
      "        [ -2.,  38.,  40.,  ...,   3.,   6.,  -2.]])\n",
      "Layer 2 Weights:\n",
      " tensor([[-41.,   1., -40.,  ..., -39.,  48.,  30.],\n",
      "        [ 81.,  38., -37.,  ...,   5.,  -9.,  84.],\n",
      "        [ -5.,  -1.,  -3.,  ...,  77., -11.,  36.],\n",
      "        ...,\n",
      "        [ 80., -75.,  -5.,  ..., 121.,  79.,  40.],\n",
      "        [-50., -33., -49.,  ...,  27.,  72., -40.],\n",
      "        [ 44.,  31.,  13.,  ...,  37.,   4., -46.]])\n",
      "Layer 3 Weights:\n",
      " tensor([[ 37., -39.,   1.,  ...,  30.,  40.,  34.],\n",
      "        [-40.,  36.,  78.,  ...,   7.,  48.,   6.],\n",
      "        [  6.,  66., -29.,  ...,   3.,  40.,   3.],\n",
      "        ...,\n",
      "        [ 37.,  -1.,  -0.,  ...,  34., -40.,  -3.],\n",
      "        [ 50.,   2.,   8.,  ...,  24.,  29.,   5.],\n",
      "        [ 85.,   3.,   3.,  ...,   0., -19.,  -2.]])\n",
      "Layer 4 Weights:\n",
      " tensor([[  51.,   40.,   36.,  -35.,   41.,  120.,   79.,  -42.,   40.,   41.,\n",
      "            4.,   -2.,   37.,   41.,  -81.,  -34.,   39.,   53.,   -3.,  -28.,\n",
      "          -35.,  -32.,   42.,   38.,  -42.,   37.,   39.,   63.,    1.,   79.,\n",
      "           38.,   37.],\n",
      "        [  42.,   41.,   31.,    1.,   52.,   42.,    2.,   83.,  -37.,    4.,\n",
      "           42.,  -32.,    4.,   75.,   48.,    3.,   14.,    3.,   37.,  -87.,\n",
      "          -34.,  -33., -121.,  -34.,  -34.,   78.,   41.,   38.,   53.,   53.,\n",
      "           -3.,  -32.],\n",
      "        [  36.,    1.,   -0.,   39.,   18.,  -45.,  -88.,   78.,  -83.,  -34.,\n",
      "           36.,    2.,    1.,   41.,   46.,    2.,  -47.,    2.,   51.,   60.,\n",
      "           38.,   47.,    4.,   83.,    1.,   47.,    5.,    3.,   37.,  -33.,\n",
      "           46.,   -2.],\n",
      "        [ -51.,    4.,   74.,   76.,   42.,  -46.,   -1.,    5.,  -44.,   -1.,\n",
      "            4.,   -1.,   42.,   55.,   37.,   76.,    2.,   37.,    2.,   40.,\n",
      "          -44.,  -77.,   48.,    1.,   -1.,   39.,   -0.,   -1.,   17.,    3.,\n",
      "           40.,   -1.],\n",
      "        [ -28., -122.,   -3.,   48.,  -15.,   77.,  -34.,   85.,   36.,    6.,\n",
      "           53.,   36.,  -35.,   61.,   40.,   -1.,  -41.,  -37.,   42.,   42.,\n",
      "           43.,   40.,    5.,   85.,  -44.,   85.,    5.,    5.,    2.,  -51.,\n",
      "          -33.,    7.],\n",
      "        [  75.,  -33.,   40.,  -36.,  -33.,   35.,   34.,  -34.,   -3.,   82.,\n",
      "            4.,    4.,   46.,  -49.,   36.,   36.,   58.,   37.,  -47.,    3.,\n",
      "            5.,   38.,  -33.,    6.,   28.,   45.,  -28.,   37., -120.,   -3.,\n",
      "            1.,   -2.],\n",
      "        [   1.,   43.,   48.,   -2.,  -33.,  -32.,  -74.,    2.,    2.,  -34.,\n",
      "           86.,   12.,   34.,   -4.,   36.,   -2.,  -11.,  -43.,  -36.,    2.,\n",
      "           -2.,   13.,    3.,   39.,   -2.,   49.,   41.,   -3.,  -37.,   -3.,\n",
      "            3.,    7.],\n",
      "        [  -7.,   44.,   37.,   -0.,   -0.,    2.,   38.,   37.,  -36.,   53.,\n",
      "           37.,   16.,   -2.,   42.,   42.,   -3.,  -33.,  -47.,  -19.,    0.,\n",
      "          -33.,   -0.,    5.,   -0.,   -7.,   84.,    5.,    4.,   35.,    6.,\n",
      "           40.,    5.],\n",
      "        [  32.,   39.,   38.,  -33.,  123.,    3.,  -27.,   51.,  -45.,   52.,\n",
      "           -3.,    6.,    3.,  -48.,   44.,   36.,   48.,    2.,   40.,  -37.,\n",
      "           -2.,   53., -124.,    3.,    2.,  -37.,   -1.,   59.,    7.,   28.,\n",
      "           41.,   37.],\n",
      "        [  53.,  -35.,    8.,    1.,    1.,  -33.,   37.,   88.,   -1.,    4.,\n",
      "           81.,   36.,   -3.,  -13.,   41.,  -36.,  -27.,   -0.,    5.,   46.,\n",
      "           75.,    7.,  -42.,  -47.,  -28.,   84.,  -41.,   -2.,   35.,   -1.,\n",
      "           17.,   -2.]])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.children()):\n",
    "        if isinstance(layer, ScalableLinear):  # Ensure that the layer is of type ScalableLinear\n",
    "            print(f\"Layer {i+1} Weights:\\n\", layer.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2233b05c-3b64-4300-86d9-f5d5df07693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ac0e02-92d0-4c72-b4c3-178bbee85e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_as_hex(model):\n",
    "    weight_matrices = [model.layer1.weight.data, model.layer2.weight.data, model.layer3.weight.data, model.layer4.weight.data]\n",
    "\n",
    "    for idx, weight_matrix in enumerate(weight_matrices, start=1):\n",
    "        # Flatten weight matrix\n",
    "        flattened_weights = weight_matrix.flatten().cpu().numpy()\n",
    "        \n",
    "        # Open corresponding file for saving weights\n",
    "        with open(f'matrix{idx}.mif', 'w') as file:\n",
    "            for weight in flattened_weights:\n",
    "                # Convert directly to integer\n",
    "                int_weight = int(weight.item())\n",
    "                # Format as 8-digit unsigned hexadecimal\n",
    "                hex_weight = f\"{int_weight & 0xFFFFFFFF:08X}\"\n",
    "                # Write only the value\n",
    "                file.write(f\"{hex_weight}\\n\")\n",
    "\n",
    "def save_random_image(X_train, y_train):\n",
    "    # Randomly select an image index\n",
    "    idx = random.randint(0, X_train.size(0) - 1)\n",
    "    print(y_train[idx])\n",
    "    \n",
    "    # Get the corresponding image data\n",
    "    image_data = X_train[idx].numpy()  # Convert to numpy array\n",
    "    \n",
    "    # Open file to save the image data\n",
    "    with open(f'random_image.txt', 'w') as file:\n",
    "        for pixel in image_data:\n",
    "            # Map binary pixel directly to integer values (0 or 1)\n",
    "            int_pixel = int(pixel)\n",
    "            # Format as 8-digit unsigned hexadecimal\n",
    "            hex_pixel = f\"{int_pixel & 0xFFFFFFFF:08X}\"\n",
    "            # Write only the value\n",
    "            file.write(f\"{hex_pixel}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebeda2fe-2ceb-4aa5-a8aa-16330e0bab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Save the weights as signed 8 hexadecimal digits in index: value pairs\n",
    "save_weights_as_hex(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f46af75-fe84-45f8-9b82-f19a098cbf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "save_random_image(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
