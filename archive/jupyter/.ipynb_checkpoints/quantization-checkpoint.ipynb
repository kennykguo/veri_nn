{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d486bccd-5198-4554-9d25-99b2644b8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e7be1392-0cdd-4d38-9f45-c25a0daa7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns data tensors for images and labels (binary values 0 and 1)\n",
    "def load_data(filepath='train.csv'):\n",
    "    data = pd.read_csv(filepath)\n",
    "    labels = data['label'].values\n",
    "    pixels = data.drop('label', axis=1).values\n",
    "    \n",
    "    # Convert to binary (0 or 1)\n",
    "    pixels = (pixels > 127).astype(np.float32)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    pixels_tensor = torch.FloatTensor(pixels)\n",
    "    labels_tensor = torch.LongTensor(labels)\n",
    "    \n",
    "    return pixels_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "20c4b9ca-9a84-4922-9ee5-1990b705286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        X (torch.Tensor): The feature tensor (pixels).\n",
    "        y (torch.Tensor): The label tensor.\n",
    "        train_ratio (float): The proportion of data to use for training.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test (torch.Tensor): Split datasets.\n",
    "    \"\"\"\n",
    "    # Calculate the split index\n",
    "    total_samples = X.shape[0]\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    test_size = total_samples - train_size\n",
    "\n",
    "    # Randomly split the dataset\n",
    "    train_indices = torch.randperm(total_samples)[:train_size]\n",
    "    test_indices = torch.randperm(total_samples)[train_size:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47414e26-6d2b-4d97-a15c-405016c19e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823459c-6f61-4840-b86c-71d0e9c3f983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67831646-2434-438a-b8ae-88893ad865ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44978fc-3d61-437c-a6ac-9213525d0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ScalableLinear layer without bias\n",
    "class ScalableLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features, dtype=torch.float32))  # Initialize weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.mm(x, self.weight.t())\n",
    "\n",
    "    def scale_weights(self, target_min, target_max):\n",
    "        \"\"\"Scale the weights of the layer to a desired integer range.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Get the min and max values of the layer's weights\n",
    "            weight_min = self.weight.min()\n",
    "            weight_max = self.weight.max()\n",
    "\n",
    "            # Compute scaling factor\n",
    "            scale = (target_max - target_min) / (weight_max - weight_min)\n",
    "            zero_point = target_min - weight_min * scale\n",
    "\n",
    "            # Apply scaling to weights\n",
    "            quantized_weights = torch.round(self.weight * scale + zero_point)\n",
    "\n",
    "            # Clip to the target range (make sure no value goes outside the desired range)\n",
    "            quantized_weights = torch.clamp(quantized_weights, target_min, target_max)\n",
    "\n",
    "            # Update weights with quantized values\n",
    "            self.weight.data = quantized_weights\n",
    "\n",
    "\n",
    " # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "# Define the neural network with scalable layers\n",
    "class ScalableNet(nn.Module):\n",
    "    def __init__(self, input_size=784):\n",
    "        super().__init__()\n",
    "        self.layer1 = ScalableLinear(input_size, 64)\n",
    "        self.layer2 = ScalableLinear(64, 64)\n",
    "        self.layer3 = ScalableLinear(64, 32)\n",
    "        self.layer4 = ScalableLinear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    # Helper function that scales weights directly\n",
    "    def scale_weights(self, target_min, target_max):\n",
    "        \"\"\"Scale weights for all layers.\"\"\"\n",
    "        self.layer1.scale_weights(target_min, target_max)\n",
    "        self.layer2.scale_weights(target_min, target_max)\n",
    "        self.layer3.scale_weights(target_min, target_max)\n",
    "        self.layer4.scale_weights(target_min, target_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f7f7b1-fa20-4125-9a86-dead9caec3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point in training loop that scales our weights\n",
    "def gradual_scale_weights(model, initial_target_min, initial_target_max, final_target_min, final_target_max, step_size, epoch, max_epochs):\n",
    "    \"\"\"\n",
    "    Gradually scale the weights of each layer after each epoch.\n",
    "    \"\"\"\n",
    "    # Compute the scaling range for this epoch based on the progress in training\n",
    "    scale_min = initial_target_min + (final_target_min - initial_target_min) * (epoch / max_epochs)\n",
    "    scale_max = initial_target_max + (final_target_max - initial_target_max) * (epoch / max_epochs)\n",
    "\n",
    "    # Apply gradual scaling to each layer\n",
    "    model.scale_weights(target_min=int(scale_min), target_max=int(scale_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "3a8a4ad6-ecdd-4aaf-8545-1a001fec219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 33600 samples\n",
      "Testing set size: 8400 samples\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "X, y = load_data('train.csv')\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, train_ratio=0.8)\n",
    "\n",
    "print(f\"Training set size: {X_train.size(0)} samples\")\n",
    "print(f\"Testing set size: {X_test.size(0)} samples\")\n",
    "\n",
    "# Train the model\n",
    "model = ScalableNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "37d98d81-ccf0-48cd-9b68-3e458dda88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "batch_size = 4096 * 2 * 2\n",
    "initial_target_min= -64\n",
    "initial_target_max= 63\n",
    "final_target_min= -32\n",
    "final_target_max= 31\n",
    "step_size= 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.1)\n",
    "n_samples = X_train.shape[0]\n",
    "n_batches = n_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "ad344b82-33c1-4e4e-bf4c-1daace77b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1421, Accuracy: 0.0944\n",
      "Epoch [2/10], Loss: 5380.9279, Accuracy: 0.1633\n",
      "Epoch [3/10], Loss: 3282.7863, Accuracy: 0.1609\n",
      "Epoch [4/10], Loss: 2145.0448, Accuracy: 0.1681\n",
      "Epoch [5/10], Loss: 1372.6731, Accuracy: 0.1910\n",
      "Epoch [6/10], Loss: 905.9057, Accuracy: 0.2171\n",
      "Epoch [7/10], Loss: 596.5300, Accuracy: 0.2249\n",
      "Epoch [8/10], Loss: 337.1610, Accuracy: 0.2298\n",
      "Epoch [9/10], Loss: 213.9863, Accuracy: 0.2350\n",
      "Epoch [10/10], Loss: 140.0001, Accuracy: 0.2428\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_X = X_train[start_idx:end_idx]\n",
    "        batch_y = y_train[start_idx:end_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pas\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / n_samples\n",
    "    accuracy = correct / n_samples\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Scale the weights using \n",
    "    # Gradual weight scaling after each epoch\n",
    "    gradual_scale_weights(model, initial_target_min, initial_target_max, final_target_min, final_target_max, step_size, epoch, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "2f83c1fc-852b-482c-a2e0-7e5a686cbd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "Layer weights min: -35.0, max: 34.0\n",
      "Layer weights min: -35.0, max: 34.0\n",
      "Layer weights min: -35.0, max: 34.0\n",
      "Layer weights min: -35.0, max: 34.0\n",
      "\n",
      "After scaling:\n",
      "Layer weights min: -35.0, max: 34.0\n",
      "Layer weights min: -35.0, max: 34.0\n",
      "Layer weights min: -35.0, max: 34.0\n",
      "Layer weights min: -35.0, max: 34.0\n"
     ]
    }
   ],
   "source": [
    "# Check min and max values before and after scaling\n",
    "print(\"Before scaling:\")\n",
    "for layer in model.children():\n",
    "    if isinstance(layer, ScalableLinear):\n",
    "        print(f\"Layer weights min: {layer.weight.min().item()}, max: {layer.weight.max().item()}\")\n",
    "\n",
    "# # Apply scaling\n",
    "# model.scale_weights(target_min=-128, target_max=127)\n",
    "\n",
    "print(\"\\nAfter scaling:\")\n",
    "for layer in model.children():\n",
    "    if isinstance(layer, ScalableLinear):\n",
    "        print(f\"Layer weights min: {layer.weight.min().item()}, max: {layer.weight.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "27b9eecd-9ebe-41de-aa78-da41b07c8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8400, 784])\n",
      "Test Loss: 7401.6953, Test Accuracy: 0.0995\n"
     ]
    }
   ],
   "source": [
    "# Test the model after scaling the weights\n",
    "def test_model(model, X_test, y_test):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(X_test.shape)\n",
    "    # Evaluate on the test set\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        loss = criterion(outputs, y_test)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == y_test).sum().item()\n",
    "        accuracy = correct / y_test.size(0)\n",
    "        \n",
    "    print(f\"Test Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "# Assuming you have the test set X_test and y_test available\n",
    "# Run the evaluation after scaling the weights\n",
    "model.scale_weights(target_min=-32, target_max=31)\n",
    "\n",
    "# Test the model after scaling\n",
    "test_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c74f7-c702-4e03-accd-c89ef7a68359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d20fe221-937b-408d-bf19-54570eeae69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Weights:\n",
      " tensor([[ -4.,   4.,  -4.,  ...,   8.,  -4.,   0.],\n",
      "        [  4.,   0.,   8.,  ...,   0.,  -8.,  15.],\n",
      "        [ 17.,   4., -13.,  ...,   8.,  11.,   8.],\n",
      "        ...,\n",
      "        [  8.,   4.,  -4.,  ...,  11., -11.,  -8.],\n",
      "        [  4., -11.,   0.,  ...,   8.,   0.,  17.],\n",
      "        [ -4.,  15.,  21.,  ...,   0.,  -4.,   4.]])\n",
      "Layer 2 Weights:\n",
      " tensor([[ 19.,  23.,  12.,  ...,  -4.,  17., -13.],\n",
      "        [  0.,  27.,   8.,  ...,   8.,   8.,   8.],\n",
      "        [ -4.,   8.,   0.,  ...,   8.,   8.,  -8.],\n",
      "        ...,\n",
      "        [ 12.,   8.,  -4.,  ...,  -8.,  -4.,  19.],\n",
      "        [ -4.,  -4.,   0.,  ...,  12., -23.,  23.],\n",
      "        [  4.,   4.,   0.,  ...,   0.,  -4.,   4.]])\n",
      "Layer 3 Weights:\n",
      " tensor([[ -4.,  -1.,  -8.,  ...,   4.,   8., -17.],\n",
      "        [ -8.,   4.,  -8.,  ...,  12.,  -4.,   8.],\n",
      "        [  0., -12.,  -8.,  ...,   8.,  12.,   4.],\n",
      "        ...,\n",
      "        [-21.,   8.,   4.,  ...,  -1.,  -8.,   4.],\n",
      "        [ -5.,  -8.,   0.,  ...,  -8., -27., -36.],\n",
      "        [ -4.,   4., -11.,  ...,  -6., -19.,   4.]])\n",
      "Layer 4 Weights:\n",
      " tensor([[ -4.,  -8.,   0., -32., -13., -12.,  23., -13., -13.,   4.,  17., -40.,\n",
      "           4.,   0.,  -4.,   4.,  21., -25.,   0.,   5.,   4.,   1.,  40.,   4.,\n",
      "          -4.,   4.,   4., -12., -23.,  -8.,   8.,  -4.],\n",
      "        [  8., -18.,   0.,   5.,   0., -12., -27.,   4.,  27.,  15.,  17.,   0.,\n",
      "           4., -13.,   4., -12.,   4.,   0.,  27.,   0.,  -4.,   4.,   0.,  -1.,\n",
      "          -8.,  -8.,  12.,  -8.,  -8.,   4.,  -8., -12.],\n",
      "        [-27.,   0., -15., -15.,  -4.,   0., -19.,  -4., -15.,  -4., -31.,   0.,\n",
      "           9., -15.,  12.,   4.,   0.,   8.,  -4.,  23., -12.,   8.,  -4.,  -4.,\n",
      "           8.,  -8.,   3.,  -8., -12.,  36.,   4., -15.],\n",
      "        [-21.,  -4.,  -4.,  -4., -27.,  15.,  25., -23.,   0.,  -4.,  23.,  -8.,\n",
      "          11.,   8.,   4.,  27.,  12.,   5.,  12.,   0., -21.,  -8.,  -8.,  -4.,\n",
      "          -4., -21.,   5.,  17.,   4., -32.,  -8., -13.],\n",
      "        [ -8., -13.,  -4.,  -4., -12.,  -8.,  -4.,   0.,  12., -13.,  -4.,  27.,\n",
      "          17., -15.,  -4., -32.,  -8.,   5.,   0.,  -4.,  23.,   4.,  -8.,   0.,\n",
      "         -13.,  19.,   8.,   0.,   0.,   8.,  -8.,  -4.],\n",
      "        [ -4.,  -8., -13.,   4., -27., -13.,  -4.,   4.,  27.,   4.,   0.,  -4.,\n",
      "           8., -11.,  -8.,  -4.,  13.,  12., -21.,   0.,   0.,  13.,  -9.,   5.,\n",
      "           0.,   4.,   4.,  13.,  12., -17.,  -4., -12.],\n",
      "        [  4.,   0., -11., -11.,  -4.,   0., -31.,  27., -13., -13.,   4., -27.,\n",
      "          12.,   8.,   0.,  12.,   0.,   0.,   0.,   8., -17.,  -8.,   0.,   0.,\n",
      "          23.,  -4.,   4.,  13.,  -4., -21.,  -8.,  -4.],\n",
      "        [ 17.,   0.,  -8.,   0.,  -4.,  -8.,   4., -23., -27.,  -4.,  12.,  12.,\n",
      "          -1.,  -4.,   0.,  -4.,  17.,  20.,   4.,   8., -12.,   0.,  17., -13.,\n",
      "         -12.,   0.,   5.,   8., -23., -13.,  13.,   0.],\n",
      "        [ -8.,  17.,   0.,   0., -13.,  -4.,  13.,   8.,   8.,  -8., -17.,   4.,\n",
      "          -8.,  -8.,  13.,  17.,   8.,  -4., -21.,  17.,  17.,  -8., -12.,   8.,\n",
      "         -13.,   4.,  -4., -32.,   0., -40.,  17.,   4.],\n",
      "        [ -8.,  21.,  -4.,   0., -12.,  27.,   4., -12., -21.,  -8.,  -4.,  -4.,\n",
      "         -10., -13., -12.,   4., -17.,  13., -12.,   4.,  36., -19.,   9.,   4.,\n",
      "         -13.,  17.,   0.,  17.,  -8.,   8.,   8.,  -8.]])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.children()):\n",
    "        if isinstance(layer, ScalableLinear):  # Ensure that the layer is of type ScalableLinear\n",
    "            print(f\"Layer {i+1} Weights:\\n\", layer.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2233b05c-3b64-4300-86d9-f5d5df07693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ac0e02-92d0-4c72-b4c3-178bbee85e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_as_hex(model):\n",
    "    weight_matrices = [model.layer1.weight.data, model.layer2.weight.data, model.layer3.weight.data, model.layer4.weight.data]\n",
    "\n",
    "    for idx, weight_matrix in enumerate(weight_matrices, start=1):\n",
    "        # Flatten weight matrix\n",
    "        flattened_weights = weight_matrix.flatten().cpu().numpy()\n",
    "        \n",
    "        # Open corresponding file for saving weights\n",
    "        with open(f'matrix{idx}.mif', 'w') as file:\n",
    "            for weight in flattened_weights:\n",
    "                # Convert directly to integer\n",
    "                int_weight = int(weight.item())\n",
    "                # Format as 8-digit unsigned hexadecimal\n",
    "                hex_weight = f\"{int_weight & 0xFFFFFFFF:08X}\"\n",
    "                # Write only the value\n",
    "                file.write(f\"{hex_weight}\\n\")\n",
    "\n",
    "def save_random_image(X_train, y_train):\n",
    "    # Randomly select an image index\n",
    "    idx = random.randint(0, X_train.size(0) - 1)\n",
    "    print(y_train[idx])\n",
    "    \n",
    "    # Get the corresponding image data\n",
    "    image_data = X_train[idx].numpy()  # Convert to numpy array\n",
    "    \n",
    "    # Open file to save the image data\n",
    "    with open(f'random_image.txt', 'w') as file:\n",
    "        for pixel in image_data:\n",
    "            # Map binary pixel directly to integer values (0 or 1)\n",
    "            int_pixel = int(pixel)\n",
    "            # Format as 8-digit unsigned hexadecimal\n",
    "            hex_pixel = f\"{int_pixel & 0xFFFFFFFF:08X}\"\n",
    "            # Write only the value\n",
    "            file.write(f\"{hex_pixel}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebeda2fe-2ceb-4aa5-a8aa-16330e0bab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Save the weights as signed 8 hexadecimal digits in index: value pairs\n",
    "save_weights_as_hex(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f46af75-fe84-45f8-9b82-f19a098cbf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "save_random_image(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
