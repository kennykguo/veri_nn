{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d486bccd-5198-4554-9d25-99b2644b8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7be1392-0cdd-4d38-9f45-c25a0daa7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns data tensors for images and labels (binary values 0 and 1)\n",
    "def load_data(filepath='train.csv'):\n",
    "    data = pd.read_csv(filepath)\n",
    "    labels = data['label'].values\n",
    "    pixels = data.drop('label', axis=1).values\n",
    "    \n",
    "    # Convert to binary (0 or 1)\n",
    "    pixels = (pixels > 127).astype(np.float32)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    pixels_tensor = torch.FloatTensor(pixels)\n",
    "    labels_tensor = torch.LongTensor(labels)\n",
    "    \n",
    "    return pixels_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c4b9ca-9a84-4922-9ee5-1990b705286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        X (torch.Tensor): The feature tensor (pixels).\n",
    "        y (torch.Tensor): The label tensor.\n",
    "        train_ratio (float): The proportion of data to use for training.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test (torch.Tensor): Split datasets.\n",
    "    \"\"\"\n",
    "    # Calculate the split index\n",
    "    total_samples = X.shape[0]\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    test_size = total_samples - train_size\n",
    "\n",
    "    # Randomly split the dataset\n",
    "    train_indices = torch.randperm(total_samples)[:train_size]\n",
    "    test_indices = torch.randperm(total_samples)[train_size:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47414e26-6d2b-4d97-a15c-405016c19e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa29b3-00b0-44d7-87cc-e955e573e422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67831646-2434-438a-b8ae-88893ad865ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a44978fc-3d61-437c-a6ac-9213525d0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ScalableLinear layer without bias\n",
    "class ScalableLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features, dtype=torch.float32))  # Initialize weights\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.weight\n",
    "\n",
    "    def scale_weights(self, target_min, target_max):\n",
    "        \"\"\"Scale the weights of the layer to a desired integer range.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Get the min and max values of the layer's weights\n",
    "            weight_min = self.weight.min()\n",
    "            weight_max = self.weight.max()\n",
    "\n",
    "            # Compute scaling factor\n",
    "            scale = (target_max - target_min) / (weight_max - weight_min)\n",
    "            zero_point = target_min - weight_min * scale\n",
    "\n",
    "            # Apply scaling to weights\n",
    "            quantized_weights = torch.round(self.weight * scale + zero_point)\n",
    "\n",
    "            # Clip to the target range (make sure no value goes outside the desired range)\n",
    "            quantized_weights = torch.clamp(quantized_weights, target_min, target_max)\n",
    "\n",
    "            # Update weights with quantized values\n",
    "            self.weight.data = quantized_weights\n",
    "\n",
    "\n",
    " # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "# Define the neural network with scalable layers\n",
    "class ScalableNet(nn.Module):\n",
    "    def __init__(self, input_size=784):\n",
    "        super().__init__()\n",
    "        self.layer1 = ScalableLinear(input_size, 64)\n",
    "        self.layer2 = ScalableLinear(64, 64)\n",
    "        self.layer3 = ScalableLinear(64, 32)\n",
    "        self.layer4 = ScalableLinear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    # Helper function that scales weights directly\n",
    "    def scale_weights(self, target_min, target_max):\n",
    "        \"\"\"Scale weights for all layers.\"\"\"\n",
    "        self.layer1.scale_weights(target_min, target_max)\n",
    "        self.layer2.scale_weights(target_min, target_max)\n",
    "        self.layer3.scale_weights(target_min, target_max)\n",
    "        self.layer4.scale_weights(target_min, target_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f7f7b1-fa20-4125-9a86-dead9caec3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point in training loop that scales our weights\n",
    "def gradual_scale_weights(model, initial_target_min, initial_target_max, final_target_min, final_target_max, step_size, epoch, max_epochs):\n",
    "    \"\"\"\n",
    "    Gradually scale the weights of each layer after each epoch.\n",
    "    \"\"\"\n",
    "    # Compute the scaling range for this epoch based on the progress in training\n",
    "    scale_min = initial_target_min + (final_target_min - initial_target_min) * (epoch / max_epochs)\n",
    "    scale_max = initial_target_max + (final_target_max - initial_target_max) * (epoch / max_epochs)\n",
    "\n",
    "    # Apply gradual scaling to each layer\n",
    "    model.scale_weights(target_min=int(scale_min), target_max=int(scale_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8ab61bd7-a473-45e8-9c9f-80b7543b05a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 37800 samples\n",
      "Testing set size: 4200 samples\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "X, y = load_data('train.csv')\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, train_ratio=0.9)\n",
    "\n",
    "print(f\"Training set size: {X_train.size(0)} samples\")\n",
    "print(f\"Testing set size: {X_test.size(0)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3a8a4ad6-ecdd-4aaf-8545-1a001fec219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 37800 samples\n",
      "Testing set size: 4200 samples\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = ScalableNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 1024\n",
    "epochs=10\n",
    "n_batches = n_samples // batch_size\n",
    "initial_target_min= -128\n",
    "initial_target_max= 127\n",
    "final_target_min= -64\n",
    "final_target_max= 64\n",
    "step_size= 0.1\n",
    "n_samples = X_train.shape[0]\n",
    "n_batches = n_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ad344b82-33c1-4e4e-bf4c-1daace77b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 7929.4462, Accuracy: 0.8280\n",
      "Epoch [2/10], Loss: 70640.1103, Accuracy: 0.8287\n",
      "Epoch [3/10], Loss: 53799.1818, Accuracy: 0.8331\n",
      "Epoch [4/10], Loss: 41673.6290, Accuracy: 0.8351\n",
      "Epoch [5/10], Loss: 40392.3432, Accuracy: 0.8372\n",
      "Epoch [6/10], Loss: 32899.6534, Accuracy: 0.8075\n",
      "Epoch [7/10], Loss: 20795.5762, Accuracy: 0.8268\n",
      "Epoch [8/10], Loss: 27728.4615, Accuracy: 0.7980\n",
      "Epoch [9/10], Loss: 17922.8936, Accuracy: 0.7774\n",
      "Epoch [10/10], Loss: 19985.3653, Accuracy: 0.7736\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_X = X_train[start_idx:end_idx]\n",
    "        batch_y = y_train[start_idx:end_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pas\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / n_samples\n",
    "    accuracy = correct / n_samples\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Scale the weights using \n",
    "    # Gradual weight scaling after each epoch\n",
    "    gradual_scale_weights(model, initial_target_min, initial_target_max, final_target_min, final_target_max, step_size, epoch, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2f83c1fc-852b-482c-a2e0-7e5a686cbd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:\n",
      "Layer weights min: -70.0, max: 70.0\n",
      "Layer weights min: -70.0, max: 70.0\n",
      "Layer weights min: -70.0, max: 70.0\n",
      "Layer weights min: -70.0, max: 70.0\n"
     ]
    }
   ],
   "source": [
    "# Check min and max values before and after scaling\n",
    "print(\"Before scaling:\")\n",
    "for layer in model.children():\n",
    "    if isinstance(layer, ScalableLinear):\n",
    "        print(f\"Layer weights min: {layer.weight.min().item()}, max: {layer.weight.max().item()}\")\n",
    "\n",
    "# # Apply scaling\n",
    "# model.scale_weights(target_min=-, target_max=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "27b9eecd-9ebe-41de-aa78-da41b07c8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 536441.6875, Test Accuracy: 0.8033\n"
     ]
    }
   ],
   "source": [
    "# Test the model after scaling the weights\n",
    "def test_model(model, X_test, y_test):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        loss = criterion(outputs, y_test)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == y_test).sum().item()\n",
    "        accuracy = correct / y_test.size(0)\n",
    "        \n",
    "    print(f\"Test Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "# Assuming you have the test set X_test and y_test available\n",
    "# Run the evaluation after scaling the weights\n",
    "model.scale_weights(target_min=-32, target_max=32)\n",
    "\n",
    "# Test the model after scaling\n",
    "test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d20fe221-937b-408d-bf19-54570eeae69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Weights:\n",
      " tensor([[ -5.,  -5., -10.,  ..., -10.,  -3.,   3.],\n",
      "        [ -3.,  -5.,   0.,  ...,   5.,   0.,  -3.],\n",
      "        [  0., -10.,   0.,  ...,   5.,   3.,   0.],\n",
      "        ...,\n",
      "        [  3.,  -3.,  10.,  ...,  -8., -10.,  -3.],\n",
      "        [  0.,  -3.,   0.,  ...,   0.,  10.,  10.],\n",
      "        [ -3., -15.,   5.,  ...,  -3.,   3.,   3.]])\n",
      "tensor([[ -5.,  -5., -10.,  ..., -10.,  -3.,   3.],\n",
      "        [ -3.,  -5.,   0.,  ...,   5.,   0.,  -3.],\n",
      "        [  0., -10.,   0.,  ...,   5.,   3.,   0.],\n",
      "        ...,\n",
      "        [  3.,  -3.,  10.,  ...,  -8., -10.,  -3.],\n",
      "        [  0.,  -3.,   0.,  ...,   0.,  10.,  10.],\n",
      "        [ -3., -15.,   5.,  ...,  -3.,   3.,   3.]])\n",
      "torch.Size([784, 64])\n",
      "Layer 2 Weights:\n",
      " tensor([[  0., -10.,   5.,  ..., -19.,   5.,  -5.],\n",
      "        [-15.,  -0., -15.,  ..., -15., -15.,   0.],\n",
      "        [  0.,  -5., -15.,  ..., -10.,  -0., -10.],\n",
      "        ...,\n",
      "        [ 15., -10.,  -5.,  ...,  -5.,   0.,   0.],\n",
      "        [-10.,   3.,  17.,  ...,  15.,  26.,   5.],\n",
      "        [-15.,  -2.,   0.,  ...,  -5.,  20.,  -5.]])\n",
      "tensor([[  0., -10.,   5.,  ..., -19.,   5.,  -5.],\n",
      "        [-15.,  -0., -15.,  ..., -15., -15.,   0.],\n",
      "        [  0.,  -5., -15.,  ..., -10.,  -0., -10.],\n",
      "        ...,\n",
      "        [ 15., -10.,  -5.,  ...,  -5.,   0.,   0.],\n",
      "        [-10.,   3.,  17.,  ...,  15.,  26.,   5.],\n",
      "        [-15.,  -2.,   0.,  ...,  -5.,  20.,  -5.]])\n",
      "torch.Size([64, 64])\n",
      "Layer 3 Weights:\n",
      " tensor([[  5., -14.,  -5.,  ..., -14.,  -5., -14.],\n",
      "        [  0.,  10.,  -9.,  ...,  15.,  17.,   5.],\n",
      "        [ -9.,   5.,  25.,  ...,  10.,   5.,   5.],\n",
      "        ...,\n",
      "        [  0.,   0.,   0.,  ...,   5.,  10.,  -5.],\n",
      "        [  2.,   0.,   0.,  ...,  10.,  15.,  -5.],\n",
      "        [ 10.,   3.,   4.,  ...,  -0.,   5.,  -9.]])\n",
      "tensor([[  5., -14.,  -5.,  ..., -14.,  -5., -14.],\n",
      "        [  0.,  10.,  -9.,  ...,  15.,  17.,   5.],\n",
      "        [ -9.,   5.,  25.,  ...,  10.,   5.,   5.],\n",
      "        ...,\n",
      "        [  0.,   0.,   0.,  ...,   5.,  10.,  -5.],\n",
      "        [  2.,   0.,   0.,  ...,  10.,  15.,  -5.],\n",
      "        [ 10.,   3.,   4.,  ...,  -0.,   5.,  -9.]])\n",
      "torch.Size([64, 32])\n",
      "Layer 4 Weights:\n",
      " tensor([[  0.,  19.,  -5.,  -2., -29.,   0., -29.,  -5.,   4., -15.],\n",
      "        [  5., -15.,   1.,   0.,  -9.,   0.,  14., -14.,  -4.,  19.],\n",
      "        [ -4.,   8.,  -2.,   5., -15., -17., -14., -14.,  11.,  -4.],\n",
      "        [ 18.,  -3.,   5., -24.,  -3.,  11.,   1.,  21.,  -5.,   5.],\n",
      "        [ 20.,  -9.,  10.,  10., -13., -10.,   5.,   0.,   9.,   5.],\n",
      "        [  0.,   6.,  20.,  -9.,   0.,   0.,  -1.,   6.,  -1.,   0.],\n",
      "        [ 20.,  -2., -13.,   0.,  12.,  -1.,   8.,   6.,  21.,   5.],\n",
      "        [-10.,  16.,  -7.,  11.,  -8.,   8.,   0.,  -5.,  -9.,   9.],\n",
      "        [ -9.,  19.,  11.,  19.,   1.,  11., -19.,  18., -27.,   0.],\n",
      "        [ -9.,  -8.,   0.,   0.,  -8.,  11., -28.,   6., -15.,   4.],\n",
      "        [-14.,   5.,   5., -14.,   5., -15.,  10., -10., -10., -20.],\n",
      "        [-18.,  -3.,  32.,   5.,  -9.,   4.,  -2.,  -5.,  -5.,  -4.],\n",
      "        [  5., -24.,   8., -19.,   5.,   5.,   6.,  22.,  -5.,  -8.],\n",
      "        [ 14., -11.,   9.,  19., -13.,  -4.,  10.,  10.,   6.,  24.],\n",
      "        [  5.,  10.,  -9.,   3.,   2.,  15.,  -5.,   5.,  14.,  -4.],\n",
      "        [ 11., -14.,   9., -19.,   5.,   2.,  10., -19.,  -5.,  -5.],\n",
      "        [ 19.,  -4.,  -5.,  -8.,   3.,   3.,   5., -13.,  -5.,   9.],\n",
      "        [ 19.,  -5.,  10.,   5.,  14.,  16.,  10.,  -4.,  10.,   5.],\n",
      "        [ -4.,   5., -13.,  29.,   5.,   3.,   8.,  16.,  25.,   0.],\n",
      "        [ -5.,  24.,  -8.,   5.,  27.,  14.,  11.,  -4.,   2.,   6.],\n",
      "        [ 11., -13.,  15.,   5.,  16.,   3.,  15.,   7.,   7.,  10.],\n",
      "        [ -8.,   5.,  -9.,  15.,  -8.,  24.,  14.,  10.,   6.,  -5.],\n",
      "        [-32.,  -4.,  -4.,  -0.,   4.,  -1.,   0.,  14.,   5., -12.],\n",
      "        [ 11.,   1.,  -9.,  -4.,  -4.,  12.,  17.,  12.,  -4.,  14.],\n",
      "        [-32.,  -2., -23., -18.,  20.,  14.,  13.,  11., -15.,  25.],\n",
      "        [ -9.,  -3., -10.,  14.,  10.,  -2.,  13.,   0.,  10.,   5.],\n",
      "        [-17.,   5.,  -9.,  -3.,  -5.,  20.,  -5.,   0.,  -8.,  -8.],\n",
      "        [ 10.,   6.,   8.,   5.,   0.,  -7.,   0.,  -4.,  -4.,   7.],\n",
      "        [ 23., -13.,   3.,  -8.,  -5.,  -5., -15.,   1.,   1.,  -6.],\n",
      "        [ 11.,  -4.,  17.,   3.,  11.,   5.,   8.,  20.,  -9.,  21.],\n",
      "        [  0.,   3.,   5.,   8.,  -3., -10.,   7., -21.,  -9.,  -1.],\n",
      "        [ -4.,  20., -14.,   5.,   0.,  29.,   5.,  20., -14.,  27.]])\n",
      "tensor([[  0.,  19.,  -5.,  -2., -29.,   0., -29.,  -5.,   4., -15.],\n",
      "        [  5., -15.,   1.,   0.,  -9.,   0.,  14., -14.,  -4.,  19.],\n",
      "        [ -4.,   8.,  -2.,   5., -15., -17., -14., -14.,  11.,  -4.],\n",
      "        [ 18.,  -3.,   5., -24.,  -3.,  11.,   1.,  21.,  -5.,   5.],\n",
      "        [ 20.,  -9.,  10.,  10., -13., -10.,   5.,   0.,   9.,   5.],\n",
      "        [  0.,   6.,  20.,  -9.,   0.,   0.,  -1.,   6.,  -1.,   0.],\n",
      "        [ 20.,  -2., -13.,   0.,  12.,  -1.,   8.,   6.,  21.,   5.],\n",
      "        [-10.,  16.,  -7.,  11.,  -8.,   8.,   0.,  -5.,  -9.,   9.],\n",
      "        [ -9.,  19.,  11.,  19.,   1.,  11., -19.,  18., -27.,   0.],\n",
      "        [ -9.,  -8.,   0.,   0.,  -8.,  11., -28.,   6., -15.,   4.],\n",
      "        [-14.,   5.,   5., -14.,   5., -15.,  10., -10., -10., -20.],\n",
      "        [-18.,  -3.,  32.,   5.,  -9.,   4.,  -2.,  -5.,  -5.,  -4.],\n",
      "        [  5., -24.,   8., -19.,   5.,   5.,   6.,  22.,  -5.,  -8.],\n",
      "        [ 14., -11.,   9.,  19., -13.,  -4.,  10.,  10.,   6.,  24.],\n",
      "        [  5.,  10.,  -9.,   3.,   2.,  15.,  -5.,   5.,  14.,  -4.],\n",
      "        [ 11., -14.,   9., -19.,   5.,   2.,  10., -19.,  -5.,  -5.],\n",
      "        [ 19.,  -4.,  -5.,  -8.,   3.,   3.,   5., -13.,  -5.,   9.],\n",
      "        [ 19.,  -5.,  10.,   5.,  14.,  16.,  10.,  -4.,  10.,   5.],\n",
      "        [ -4.,   5., -13.,  29.,   5.,   3.,   8.,  16.,  25.,   0.],\n",
      "        [ -5.,  24.,  -8.,   5.,  27.,  14.,  11.,  -4.,   2.,   6.],\n",
      "        [ 11., -13.,  15.,   5.,  16.,   3.,  15.,   7.,   7.,  10.],\n",
      "        [ -8.,   5.,  -9.,  15.,  -8.,  24.,  14.,  10.,   6.,  -5.],\n",
      "        [-32.,  -4.,  -4.,  -0.,   4.,  -1.,   0.,  14.,   5., -12.],\n",
      "        [ 11.,   1.,  -9.,  -4.,  -4.,  12.,  17.,  12.,  -4.,  14.],\n",
      "        [-32.,  -2., -23., -18.,  20.,  14.,  13.,  11., -15.,  25.],\n",
      "        [ -9.,  -3., -10.,  14.,  10.,  -2.,  13.,   0.,  10.,   5.],\n",
      "        [-17.,   5.,  -9.,  -3.,  -5.,  20.,  -5.,   0.,  -8.,  -8.],\n",
      "        [ 10.,   6.,   8.,   5.,   0.,  -7.,   0.,  -4.,  -4.,   7.],\n",
      "        [ 23., -13.,   3.,  -8.,  -5.,  -5., -15.,   1.,   1.,  -6.],\n",
      "        [ 11.,  -4.,  17.,   3.,  11.,   5.,   8.,  20.,  -9.,  21.],\n",
      "        [  0.,   3.,   5.,   8.,  -3., -10.,   7., -21.,  -9.,  -1.],\n",
      "        [ -4.,  20., -14.,   5.,   0.,  29.,   5.,  20., -14.,  27.]])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.children()):\n",
    "        if isinstance(layer, ScalableLinear):  # Ensure that the layer is of type ScalableLinear\n",
    "            print(f\"Layer {i+1} Weights:\\n\", layer.weight.data)\n",
    "            print(layer.weight.data)\n",
    "            print(layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a7ac0e02-92d0-4c72-b4c3-178bbee85e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_as_hex(model):\n",
    "    weight_matrices = [model.layer1.weight.data, model.layer2.weight.data, model.layer3.weight.data, model.layer4.weight.data]\n",
    "\n",
    "    for idx, weight_matrix in enumerate(weight_matrices, start=1):\n",
    "        # Flatten weight matrix\n",
    "        flattened_weights = weight_matrix.flatten().cpu().numpy()\n",
    "        \n",
    "        # Open corresponding file for saving weights\n",
    "        with open(f'matrix{idx}.mif', 'w') as file:\n",
    "            for weight in flattened_weights:\n",
    "                # Convert directly to integer\n",
    "                int_weight = int(weight.item())\n",
    "                # Format as 8-digit unsigned hexadecimal\n",
    "                hex_weight = f\"{int_weight & 0xFFFFFFFF:08X}\"\n",
    "                # Write only the value\n",
    "                file.write(f\"{hex_weight}\\n\")\n",
    "save_weights_as_hex(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "149db81e-a72e-4fac-867a-06cec47ddb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_visualize(model, X_test, y_test, index):\n",
    "    \"\"\"\n",
    "    Tests the model on a single sample from X_test and visualizes the digit image.\n",
    "    \n",
    "    Parameters:\n",
    "    model (ScalableNet): The trained model to be tested.\n",
    "    X_test (torch.Tensor): The test set features.\n",
    "    y_test (torch.Tensor): The test set labels.\n",
    "    index (int): The index of the sample to visualize and predict.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Extract the sample at the specified index\n",
    "    sample = X_test[index].unsqueeze(0)  # Shape (1, 784)\n",
    "    label = y_test[index].item()\n",
    "\n",
    "    # Predict the label\n",
    "    with torch.no_grad():\n",
    "        output = model(sample)\n",
    "        print(output)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        predicted_label = predicted.item()\n",
    "\n",
    "    # Visualize the image\n",
    "    visualize_digit(sample.numpy().flatten())\n",
    "    \n",
    "    # Print the actual and predicted labels\n",
    "    print(f\"Actual Label: {label}, Predicted Label: {predicted_label}\")\n",
    "\n",
    "def visualize_digit(tensor):\n",
    "    \"\"\"\n",
    "    Visualize a digit represented by a (1, 784) tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (numpy.ndarray): A (1, 784) numpy array representing the digit.\n",
    "    \"\"\"\n",
    "    # Reshape the tensor to a 28x28 matrix\n",
    "    digit_image = tensor.reshape(28, 28)\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.imshow(digit_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b5669993-346b-413a-a5e9-79aa1a81ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20710928., -8142275.,  5900262.,  6699273.,  2516099.,  3886994.,\n",
      "          4830562.,  9627337., 12788586.,  9228000.]])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAF00lEQVR4nO3cwWocOxRF0daj//+X9WYbMnOJlEoprzV2sGg3bO4gZ8w55wcAPp/Pf08/AIBziAIAEQUAIgoARBQAiCgAEFEAIKIAQL4//cExxp3vAOBmP/m/yi4FACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJDv0w+AO8w5n37CXzfGePoJ/AIuBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEIN4HO+N43YrVj4HI3pc5VIAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgAxiMc2hu32M6LHVS4FACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQg3gsOX3cbteo2+mfA1zlUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFAGIlleOXPnctnq5Yedvpnze/m0sBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDEIB7wh5XBvpNHC7nGpQBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFAGIQj22Mpr2XEb33cCkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYAYxHuZlWEy9to5BOf7wFUuBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIFZSWbJz6ZN1K3+nXcuqq7/Hd+9eLgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUA8n36AcBZxhiX/82c84aX8ASXAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADI9+kHAGeZcz79BB7kUgAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCADGIx5KV0bQxxg0v4V/l+3AmlwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIhBvJdZGRlbGbdbsfp7DKet2/W35T1cCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIAbxON7KqNvJI3pvHKk7+fPmGpcCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQK6ksLVyevvR5+vtOZvH0d3MpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAGMRjyRtH9E5nqI4dXAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACAG8djGoBucz6UAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFAPL96Q/OOe98BwAHcCkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJD/ATlkWyb+KzAFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 0, Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Usage Example:\n",
    "# Assuming X_test and y_test are torch tensors\n",
    "# index = 5  # Example index you want to test and visualize\n",
    "idx = 3\n",
    "test_and_visualize(model, X_test, y_test, index=idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
